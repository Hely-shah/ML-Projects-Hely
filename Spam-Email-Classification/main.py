# -*- coding: utf-8 -*-
"""main

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1qHcosSw7TEeMynZMB3yVF6TQ0z3GFCmd
"""

import pandas as pd
from sklearn.model_selection import train_test_split

emails_df = pd.read_csv('emails.csv')
print("Emails Dataset:")
print(emails_df.shape)
print(emails_df['spam'].value_counts(normalize=True))

students_df = pd.read_csv('Student_performance_data _.csv')
print("\nStudent Performance Dataset:")
print(students_df.shape)
print(students_df['GradeClass'].value_counts(normalize=True))

email_train, email_test = train_test_split(emails_df, test_size=0.2, stratify=emails_df['spam'], random_state=42)
student_train, student_test = train_test_split(students_df, test_size=0.2, stratify=students_df['GradeClass'], random_state=42)

from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.preprocessing import LabelEncoder

X_email_train = email_train['text']
y_email_train = email_train['spam']
X_email_test = email_test['text']
y_email_test = email_test['spam']

vectorizer = TfidfVectorizer(stop_words='english', max_df=0.9)
X_email_train_tfidf = vectorizer.fit_transform(X_email_train)
X_email_test_tfidf = vectorizer.transform(X_email_test)

from sklearn.preprocessing import StandardScaler

X_student_train = student_train.drop(columns=['GradeClass'])
y_student_train = student_train['GradeClass']
X_student_test = student_test.drop(columns=['GradeClass'])
y_student_test = student_test['GradeClass']

X_student_train_encoded = pd.get_dummies(X_student_train)
X_student_test_encoded = pd.get_dummies(X_student_test)

X_student_train_encoded, X_student_test_encoded = X_student_train_encoded.align(X_student_test_encoded, join='left', axis=1, fill_value=0)

scaler = StandardScaler()
X_student_train_scaled = scaler.fit_transform(X_student_train_encoded)
X_student_test_scaled = scaler.transform(X_student_test_encoded)

from imblearn.over_sampling import SMOTE

smote = SMOTE(random_state=42)
X_student_train_resampled, y_student_train_resampled = smote.fit_resample(X_student_train_scaled, y_student_train)

print("TF-IDF Shape (Train):", X_email_train_tfidf.shape)
print("TF-IDF Shape (Test):", X_email_test_tfidf.shape)

print("Encoded + Scaled Student Train Shape:", X_student_train_scaled.shape)
print("Encoded + Scaled Student Test Shape:", X_student_test_scaled.shape)

from sklearn.linear_model import LogisticRegression
from sklearn.naive_bayes import MultinomialNB
from sklearn.svm import SVC
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import GridSearchCV
from sklearn.metrics import classification_report, f1_score, precision_score

log_params = {'C': [0.1, 1, 10], 'penalty': ['l2']}
log_model = GridSearchCV(LogisticRegression(max_iter=1000), log_params, cv=5, scoring='f1')
log_model.fit(X_email_train_tfidf, y_email_train)

print("Best Params - Logistic Regression:", log_model_student.best_params_)
print("Best Params - Decision Tree:", dt_model_student.best_params_)
print("Best Params - Random Forest:", rf_model_student.best_params_)

nb_params = {'alpha': [0.1, 1.0, 2.0], 'fit_prior': [True, False]}
nb_model = GridSearchCV(MultinomialNB(), nb_params, cv=5, scoring='f1')
nb_model.fit(X_email_train_tfidf, y_email_train)

svm_params = {'C': [1, 10], 'kernel': ['linear']}
svm_model = GridSearchCV(SVC(), svm_params, cv=5, scoring='f1')
svm_model.fit(X_email_train_tfidf, y_email_train)

rf_params = {'n_estimators': [100, 200], 'max_depth': [None, 10]}
rf_model = GridSearchCV(RandomForestClassifier(), rf_params, cv=5, scoring='f1')
rf_model.fit(X_email_train_tfidf, y_email_train)

models_email = {
    "Logistic Regression": log_model,
    "Naive Bayes": nb_model,
    "SVM": svm_model,
    "Random Forest": rf_model
}

print("EMAIL DATASET - TEST RESULTS")
for name, model in models_email.items():
    preds = model.predict(X_email_test_tfidf)
    f1 = f1_score(y_email_test, preds)
    precision = precision_score(y_email_test, preds)
    print(f"{name} - F1 Score: {f1:.4f}, Precision: {precision:.4f}")

from sklearn.metrics import classification_report

print("SVM - Classification Report on Email Dataset")
print(classification_report(y_email_test, svm_model.predict(X_email_test_tfidf)))

from sklearn.metrics import roc_curve, auc
import matplotlib.pyplot as plt

plt.figure(figsize=(8, 6))
for name, model in models_email.items():
    if hasattr(model, "predict_proba"):
        probs = model.predict_proba(X_email_test_tfidf)[:, 1]
    elif hasattr(model, "decision_function"):
        probs = model.decision_function(X_email_test_tfidf)
        probs = (probs - probs.min()) / (probs.max() - probs.min())
    else:
        continue
    fpr, tpr, _ = roc_curve(y_email_test, probs)
    roc_auc = auc(fpr, tpr)
    plt.plot(fpr, tpr, label=f"{name} (AUC = {roc_auc:.2f})")

plt.plot([0, 1], [0, 1], linestyle="--")
plt.title("ROC Curve – Emails Dataset")
plt.xlabel("False Positive Rate")
plt.ylabel("True Positive Rate")
plt.legend()
plt.grid(True)
plt.tight_layout()
plt.show()

from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import f1_score
from sklearn.model_selection import GridSearchCV

log_params = {'C': [0.1, 1, 10], 'solver': ['lbfgs']}
log_model = GridSearchCV(LogisticRegression(multi_class='multinomial', max_iter=1000), log_params, cv=5, scoring='f1_macro')
log_model.fit(X_student_train_scaled, y_student_train)

dt_params = {'max_depth': [5, 10, None], 'min_samples_split': [2, 5]}
dt_model = GridSearchCV(DecisionTreeClassifier(), dt_params, cv=5, scoring='f1_macro')
dt_model.fit(X_student_train_scaled, y_student_train)

rf_params = {'n_estimators': [100, 200], 'max_features': ['sqrt', 'log2']}
rf_model = GridSearchCV(RandomForestClassifier(), rf_params, cv=5, scoring='f1_macro')
rf_model.fit(X_student_train_scaled, y_student_train)

knn_params = {'n_neighbors': [3, 5, 7], 'weights': ['uniform', 'distance']}
knn_model = GridSearchCV(KNeighborsClassifier(), knn_params, cv=5, scoring='f1_macro')
knn_model.fit(X_student_train_scaled, y_student_train)

models_student = {
    "Logistic Regression": log_model,
    "Decision Tree": dt_model,
    "Random Forest": rf_model,
    "KNN": knn_model
}

import time

train_times = {}
test_times = {}

for name, model in models_student.items():
    start = time.time()
    model.fit(X_student_train_scaled, y_student_train)
    train_times[name] = time.time() - start

    start = time.time()
    _ = model.predict(X_student_test_scaled)
    test_times[name] = time.time() - start

plt.figure(figsize=(8, 4))
sns.barplot(x=list(train_times.keys()), y=list(train_times.values()))
plt.title("Training Time – Student Dataset")
plt.ylabel("Seconds")
plt.xticks(rotation=15)
plt.show()

plt.figure(figsize=(8, 4))
sns.barplot(x=list(test_times.keys()), y=list(test_times.values()))
plt.title("Testing Time – Student Dataset")
plt.ylabel("Seconds")
plt.xticks(rotation=15)
plt.show()

print("STUDENT DATASET - TEST RESULTS")
for name, model in models_student.items():
    preds = model.predict(X_student_test_scaled)
    f1_macro = f1_score(y_student_test, preds, average='macro')
    f1_weighted = f1_score(y_student_test, preds, average='weighted')
    print(f"{name} - Macro F1: {f1_macro:.4f}, Weighted F1: {f1_weighted:.4f}")

import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import confusion_matrix

svm_preds = svm_model.predict(X_email_test_tfidf)
cm_email = confusion_matrix(y_email_test, svm_preds)

plt.figure(figsize=(6,4))
sns.heatmap(cm_email, annot=True, fmt='d', cmap='Blues')
plt.title('Confusion Matrix - Emails (SVM)')
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.show()

f1_scores_email = {
    "Logistic Regression": f1_score(y_email_test, models_email["Logistic Regression"].predict(X_email_test_tfidf)),
    "Naive Bayes": f1_score(y_email_test, models_email["Naive Bayes"].predict(X_email_test_tfidf)),
    "SVM": f1_score(y_email_test, models_email["SVM"].predict(X_email_test_tfidf)),
    "Random Forest": f1_score(y_email_test, models_email["Random Forest"].predict(X_email_test_tfidf))
}

plt.figure(figsize=(8, 4))
sns.barplot(x=list(f1_scores_email.keys()), y=list(f1_scores_email.values()))
plt.title('Email Dataset – F1 Score Comparison')
plt.ylim(0.9, 1.0)
plt.ylabel('F1 Score')
plt.xticks(rotation=15)
plt.show()

from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.model_selection import GridSearchCV
from sklearn.metrics import f1_score, confusion_matrix
import matplotlib.pyplot as plt
import seaborn as sns

log_params = {'C': [0.1, 1, 10], 'solver': ['lbfgs']}
log_model_student = GridSearchCV(LogisticRegression(multi_class='multinomial', max_iter=1000), log_params, cv=5, scoring='f1_macro')
log_model_student.fit(X_student_train_resampled, y_student_train_resampled)

dt_params = {'max_depth': [5, 10, None], 'min_samples_split': [2, 5]}
dt_model_student = GridSearchCV(DecisionTreeClassifier(), dt_params, cv=5, scoring='f1_macro')
dt_model_student.fit(X_student_train_scaled, y_student_train)

rf_params = {'n_estimators': [100, 200], 'max_features': ['sqrt', 'log2']}
rf_model_student = GridSearchCV(RandomForestClassifier(), rf_params, cv=5, scoring='f1_macro')
rf_model_student.fit(X_student_train_scaled, y_student_train)

knn_params = {'n_neighbors': [3, 5, 7], 'weights': ['uniform', 'distance']}
knn_model_student = GridSearchCV(KNeighborsClassifier(), knn_params, cv=5, scoring='f1_macro')
knn_model_student.fit(X_student_train_scaled, y_student_train)

dt_preds = dt_model_student.predict(X_student_test_scaled)
cm_student = confusion_matrix(y_student_test, dt_preds)

plt.figure(figsize=(6,4))
sns.heatmap(cm_student, annot=True, fmt='d', cmap='Greens')
plt.title('Confusion Matrix - Students (Decision Tree)')
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.show()

f1_scores_student = {
    "Logistic Regression": f1_score(y_student_test, log_model_student.predict(X_student_test_scaled), average='macro'),
    "Decision Tree": f1_score(y_student_test, dt_model_student.predict(X_student_test_scaled), average='macro'),
    "Random Forest": f1_score(y_student_test, rf_model_student.predict(X_student_test_scaled), average='macro'),
    "KNN": f1_score(y_student_test, knn_model_student.predict(X_student_test_scaled), average='macro')
}

plt.figure(figsize=(8,4))
sns.barplot(x=list(f1_scores_student.keys()), y=list(f1_scores_student.values()))
plt.title('Student Dataset – Macro F1 Score Comparison')
plt.ylim(0.3, 1.0)
plt.ylabel('Macro F1 Score')
plt.xticks(rotation=15)
plt.show()

# ✅ ADD-ON 2: Feature Importance Plot – Student Dataset (Random Forest)
import numpy as np

importances = rf_model_student.best_estimator_.feature_importances_
features = X_student_train_encoded.columns
sorted_idx = np.argsort(importances)[::-1][:10]

plt.figure(figsize=(8, 4))
sns.barplot(x=importances[sorted_idx], y=features[sorted_idx])
plt.title("Top 10 Important Features – Random Forest (Student Dataset)")
plt.xlabel("Importance Score")
plt.tight_layout()
plt.show()

from sklearn.model_selection import learning_curve
import numpy as np

train_sizes, train_scores, test_scores = learning_curve(
    dt_model,
    X_student_train_scaled,
    y_student_train,
    cv=5,
    scoring='f1_macro',
    train_sizes=np.linspace(0.1, 1.0, 10),
    n_jobs=-1
)

train_scores_mean = np.mean(train_scores, axis=1)
test_scores_mean = np.mean(test_scores, axis=1)

plt.figure(figsize=(8, 5))
plt.plot(train_sizes, train_scores_mean, label="Training score")
plt.plot(train_sizes, test_scores_mean, label="Cross-validation score")
plt.title("Learning Curve – Decision Tree (Student Dataset)")
plt.xlabel("Training Set Size")
plt.ylabel("F1 Macro Score")
plt.legend()
plt.grid(True)
plt.tight_layout()
plt.show()